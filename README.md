# ðŸ“Š Narrative Analysis MVP
A lightweight system for extracting **overall summaries**, **dominant narratives**, and **representative comments** from large batches of Facebook comments using a **local Qwen2.5-7B model**.

This MVP includes:

- ðŸš€ Streamlit user interface  
- ðŸ§  Local LLM backend (Qwen2.5-7B-Instruct)  
- ðŸ§¹ A JSON restructuring tool for normalization  
- ðŸ“¦ Modular backend analysis engine  
- ðŸ“ Support for JSON uploads or manual text input  

# How to run ðŸš€

- Pull analysis.py restructure.py ui.py
- Run restructure-emoji.py --> prompts for JSON selection --> select raw JSON file from desktop --> saves structured JSON on desktop
- Run [streamlit run ui.py] --> opens streamlit ui --> upload structured JSON file --> click Run Narrative Analysis (takes a few minutes)
- View results --> results are downloadable / saved in root directory data/fb_comments

---

# ðŸ“¥ 1. Data Collection

This system expects Facebook comments in JSON format.  
Each comment entry must include a `"text"` field.

Example raw item:

```json
{
  "id": "1913950356145953","typename": "FB_COMMENT","text": "Na cruise we come catch for this country I swear ðŸ˜‚ðŸ˜‚ðŸ˜‚" .. ... ..... .......
}
```

---

# ðŸ“ 2. Repository Structure

Your project should follow this layout:

```
project_root/
â”‚
â”œâ”€â”€ ui.py                         # Streamlit interface
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ analysis.py               # Main narrative analysis logic
â”‚
â”œâ”€â”€ restructure-emoji.py          # Data normalization tool
â”‚
â”œâ”€â”€ qwen2.5_7b/                   # Local Qwen2.5-7B-Instruct model folder
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ fb_comments.json    # Output from restructure script
â”‚
â””â”€â”€ README.md
```

# ðŸ§¹ 3. Structure JSON

Before running the analysis, you must clean and standardize the JSON using: `restructure-emoji.py`


```

> âœ… This ensures maximum compatibility with the UI and backend.

```

# â–¶ï¸ 4. Running the Streamlit Interface

From the project root, run:

```bash
streamlit run ui.py
```

Streamlit will launch and show:

```
Local URL: http://localhost:8501
```

Autoopens / Open the link in your browser.

---

# ðŸ–¥ï¸ 5. Using the UI

### Step 1 â€” Choose Input
Select:

- **Paste text** (one comment per line)  
- **Upload JSON file**  

The UI automatically extracts valid comments.

### Step 2 â€” Preview
You'll see:

- Number of comments detected  
- First 10 comments for validation  

### Step 3 â€” Run Analysis
Click:

```
ðŸš€ Run Narrative Analysis
```

The backend produces:

- ðŸ§© Overall Summary  
- ðŸ“š Dominant Narratives  
- ðŸ’¬ Example Comments  
- ðŸ§¾ JSON Output (download available)

### Step 4 â€” Export
You can download:

```json
{
  "overall_summary": "...",
  "dominant_narratives": ["...", "..."],
  "example_comments": ["...", "..."]
}
```

---

# âš™ï¸ 6. Backend Processing Flow

Execution pipeline:

```
Raw Comments â†’ Clean â†’ Chunk â†’ LLM Summaries â†’ Merge â†’ Final Narratives JSON
```

### Internally, the backend:

1. Loads Qwen2.5-7B into GPU memory  
2. Splits comments into manageable chunks  
3. Generates summaries for each chunk  
4. Merges narratives into a single output  
5. Normalizes the output into:
   - One overall summary  
   - 3â€“6 dominant narratives  
   - 2â€“5 example comments  

> ðŸ§  Only clean structured JSON is exposed to the UI.

---

# ðŸ“¦ 7. Requirements

Install dependencies:

```bash
pip install streamlit transformers accelerate torch pydantic
```

Also ensure you have the Qwen model downloaded:

```
qwen2.5_7b/
```

---
# ðŸ‘‘ Repo POC 

* Repo Owner: Melissa Vixama
* Team: AF-ST
